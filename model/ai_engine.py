"""AI Engine module for handling OpenAI chat completions requests.

This module defines the :class:`AIEngine` class, which is responsible for
communicating with the OpenAI API. It exposes a simple interface that accepts a
conversation history and returns the assistant's reply. The implementation
follows the Model component in the Model-View-Controller (MVC) architecture.
"""
from __future__ import annotations

from dataclasses import dataclass, field
import json
import os
from typing import Iterable, MutableMapping, Sequence

import requests


class AIEngineError(RuntimeError):
    """Raised when the OpenAI API request fails or returns an invalid response."""


@dataclass(slots=True)
class AIEngine:
    """Simple wrapper around OpenAI's Chat Completions endpoint.

    Parameters
    ----------
    model_name:
        The OpenAI model identifier. Defaults to ``"gpt-4o-mini"`` but may be
        changed (e.g., to ``"gpt-3.5-turbo"``) to use a different model.
    api_base_url:
        Base URL for the OpenAI API. Override this if you are using a proxy.
    timeout_seconds:
        Number of seconds to wait before aborting a request.
    """

    model_name: str = "gpt-4o-mini"
    api_base_url: str = "https://api.openai.com/v1"
    timeout_seconds: int = 30
    _session: requests.Session = field(default_factory=requests.Session, init=False, repr=False)

    def generate_response(self, messages: Sequence[MutableMapping[str, str]]) -> str:
        """Send a conversation history to the OpenAI API and return the response.

        Parameters
        ----------
        messages:
            An iterable of chat messages where each message is a mapping with a
            ``"role"`` (``"user"``, ``"assistant"``, or ``"system"``) and a
            ``"content"`` string.

        Returns
        -------
        str
            The assistant's reply generated by the OpenAI model.

        Raises
        ------
        AIEngineError
            If the API key is missing, the request fails, or the response is
            malformed.
        """

        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise AIEngineError(
                "Missing OPENAI_API_KEY environment variable. Please export your "
                "OpenAI API key before running the chatbot."
            )

        endpoint = f"{self.api_base_url.rstrip('/')}/chat/completions"
        payload = {
            "model": self.model_name,
            "messages": list(messages),
        }
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

        try:
            response = self._session.post(
                endpoint, data=json.dumps(payload), headers=headers, timeout=self.timeout_seconds
            )
            response.raise_for_status()
        except requests.exceptions.Timeout as exc:  # pragma: no cover - runtime scenario
            raise AIEngineError(
                "Timed out while waiting for the OpenAI API. Please try again later."
            ) from exc
        except requests.exceptions.RequestException as exc:  # pragma: no cover - runtime scenario
            raise AIEngineError(
                "An error occurred while communicating with the OpenAI API."
            ) from exc

        try:
            body = response.json()
        except json.JSONDecodeError as exc:  # pragma: no cover - runtime scenario
            raise AIEngineError("Received an invalid JSON response from the OpenAI API.") from exc

        try:
            return body["choices"][0]["message"]["content"].strip()
        except (KeyError, IndexError, TypeError) as exc:  # pragma: no cover - runtime scenario
            raise AIEngineError("The OpenAI API returned an unexpected response format.") from exc

    def close(self) -> None:
        """Release any HTTP resources held by the internal session."""

        self._session.close()

    def __enter__(self) -> "AIEngine":  # pragma: no cover - simple convenience wrapper
        """Support usage as a context manager."""

        return self

    def __exit__(self, *_exc_info: Iterable[object]) -> None:  # pragma: no cover - simple convenience
        """Automatically close the session when leaving the context manager."""

        self.close()
